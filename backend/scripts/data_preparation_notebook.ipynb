{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0de72419",
   "metadata": {},
   "source": [
    "# Women Risk Predictor - Data Preparation\n",
    "\n",
    "This notebook covers the complete data preparation pipeline for the women harassment risk prediction project.\n",
    "\n",
    "## Overview\n",
    "This notebook includes:\n",
    "1. **Load Dataset** - Import raw data from CSV file\n",
    "2. **Data Exploration** - Understand the structure and content of the dataset\n",
    "3. **Handle Missing Values** - Identify and handle missing data\n",
    "4. **Remove Duplicates** - Clean duplicate entries\n",
    "5. **Encode Categorical Variables** - Convert categorical features to numerical format\n",
    "6. **Save Cleaned Data** - Export the cleaned dataset for next steps\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2579b48",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd75a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60d2dca",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "\n",
    "Load the raw dataset from the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce0fb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "data_path = \"../data/women_risk.csv\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LOADING DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"\\nDataset loaded successfully!\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Number of Rows: {data.shape[0]}\")\n",
    "print(f\"Number of Columns: {data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdecae48",
   "metadata": {},
   "source": [
    "## 3. Data Exploration\n",
    "\n",
    "Explore the dataset to understand its structure, content, and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b17fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of the dataset:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9d1e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"Dataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e302b222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display column names\n",
    "print(\"Column Names:\")\n",
    "for i, col in enumerate(data.columns, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f528927",
   "metadata": {},
   "source": [
    "## 4. Check for Missing Values\n",
    "\n",
    "Identify and handle any missing values in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=\" * 60)\n",
    "print(\"CHECKING MISSING DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "missing = data.isnull().sum()\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(missing)\n",
    "\n",
    "if missing.sum() > 0:\n",
    "    print(f\"\\n‚ö†Ô∏è Total missing values: {missing.sum()}\")\n",
    "    print(\"\\nDropping rows with missing values...\")\n",
    "    data = data.dropna()\n",
    "    print(f\"‚úÖ New shape after dropping missing values: {data.shape}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc10f4a7",
   "metadata": {},
   "source": [
    "## 5. Remove Duplicates\n",
    "\n",
    "Remove any duplicate rows from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15429319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "print(\"=\" * 60)\n",
    "print(\"REMOVING DUPLICATES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "initial_rows = len(data)\n",
    "data = data.drop_duplicates()\n",
    "final_rows = len(data)\n",
    "\n",
    "duplicates_removed = initial_rows - final_rows\n",
    "\n",
    "print(f\"\\nüìä Initial rows: {initial_rows}\")\n",
    "print(f\"üìä Duplicates removed: {duplicates_removed}\")\n",
    "print(f\"‚úÖ Final shape: {data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd86d54e",
   "metadata": {},
   "source": [
    "## 6. Encode Categorical Variables\n",
    "\n",
    "Convert categorical variables to numerical format using Label Encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "print(\"=\" * 60)\n",
    "print(\"ENCODING CATEGORICAL VARIABLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "if categorical_cols:\n",
    "    print(f\"\\nüìã Categorical columns found: {categorical_cols}\")\n",
    "    \n",
    "    label_encoders = {}\n",
    "    \n",
    "    for col in categorical_cols:\n",
    "        print(f\"\\nüîÑ Encoding '{col}'...\")\n",
    "        print(f\"   Unique values before encoding: {data[col].nunique()}\")\n",
    "        \n",
    "        le = LabelEncoder()\n",
    "        data[col] = le.fit_transform(data[col])\n",
    "        label_encoders[col] = le\n",
    "        \n",
    "        print(f\"   ‚úÖ Encoding completed for '{col}'\")\n",
    "    \n",
    "    # Save label encoders for later use\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    joblib.dump(label_encoders, '../models/label_encoders.pkl')\n",
    "    print(\"\\n‚úÖ Label encoders saved to '../models/label_encoders.pkl'\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No categorical columns found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b757d39",
   "metadata": {},
   "source": [
    "## 7. Save Cleaned Data\n",
    "\n",
    "Save the cleaned and prepared dataset for the next stage of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74c982c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned data\n",
    "output_path = \"../data/women_risk_cleaned.csv\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAVING CLEANED DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Cleaned data saved to: {output_path}\")\n",
    "print(f\"‚úÖ Final shape: {data.shape}\")\n",
    "print(f\"‚úÖ Rows: {data.shape[0]}\")\n",
    "print(f\"‚úÖ Columns: {data.shape[1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"DATA PREPARATION COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
