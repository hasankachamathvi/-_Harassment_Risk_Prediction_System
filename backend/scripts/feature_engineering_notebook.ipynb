{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5536773b",
   "metadata": {},
   "source": [
    "# Women Risk Predictor - Feature Engineering\n",
    "\n",
    "This notebook covers the feature engineering pipeline for the women harassment risk prediction project.\n",
    "\n",
    "## Overview\n",
    "This notebook includes:\n",
    "1. **Load Cleaned Data** - Import the cleaned dataset\n",
    "2. **Correlation Analysis** - Analyze feature correlations with target variable\n",
    "3. **Create New Features** - Engineer new features from existing ones\n",
    "4. **Scale Numeric Features** - Standardize numerical features\n",
    "5. **Split Features and Target** - Separate features from target variable\n",
    "6. **Save Processed Data** - Export the engineered dataset for model training\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93e334a",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142e4ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de2ff2e",
   "metadata": {},
   "source": [
    "## 2. Load Cleaned Data\n",
    "\n",
    "Load the cleaned dataset from the previous data preparation step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b415dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned data\n",
    "data_path = \"../data/women_risk_cleaned.csv\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"LOADING CLEANED DATASET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset loaded successfully!\")\n",
    "print(f\"Shape: {data.shape}\")\n",
    "print(f\"Number of Rows: {data.shape[0]}\")\n",
    "print(f\"Number of Columns: {data.shape[1]}\")\n",
    "\n",
    "# Display first few rows\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52d10d6",
   "metadata": {},
   "source": [
    "## 3. Correlation Analysis\n",
    "\n",
    "Analyze the correlation between features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33a45e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "print(\"=\" * 60)\n",
    "print(\"CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Calculate correlation matrix\n",
    "corr_matrix = data.corr()\n",
    "\n",
    "# Visualize correlation heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            fmt='.2f', square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Heatmap', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n‚úÖ Correlation heatmap displayed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139c531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation with target variable\n",
    "target_col = 'risk'\n",
    "\n",
    "if target_col in corr_matrix.columns:\n",
    "    print(f\"\\nCorrelation with target variable ('{target_col}'):\")\n",
    "    target_corr = corr_matrix[target_col].sort_values(ascending=False)\n",
    "    print(target_corr)\n",
    "    \n",
    "    # Bar plot of correlations with target\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    target_corr_filtered = target_corr[target_corr.index != target_col]\n",
    "    target_corr_filtered.plot(kind='barh', color='steelblue')\n",
    "    plt.title(f'Feature Correlation with {target_col}', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Correlation Coefficient', fontsize=12)\n",
    "    plt.ylabel('Features', fontsize=12)\n",
    "    plt.grid(axis='x', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è Warning: Target column '{target_col}' not found!\")\n",
    "    print(f\"Available columns: {data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb7a39",
   "metadata": {},
   "source": [
    "## 4. Create New Features\n",
    "\n",
    "Engineer new features from existing ones to improve model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579b14f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features\n",
    "print(\"=\" * 60)\n",
    "print(\"CREATING NEW FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "initial_features = data.shape[1]\n",
    "\n",
    "# Example: Create interaction features if columns exist\n",
    "# Customize based on your actual dataset columns\n",
    "\n",
    "if 'age' in data.columns and 'past_incidents' in data.columns:\n",
    "    data['risk_score'] = data['age'] * data['past_incidents']\n",
    "    print(\"\\n‚úÖ Created 'risk_score' = age * past_incidents\")\n",
    "\n",
    "if 'public_transport_usage' in data.columns and 'time_of_day' in data.columns:\n",
    "    data['transport_time_interaction'] = data['public_transport_usage'] * data['time_of_day']\n",
    "    print(\"‚úÖ Created 'transport_time_interaction' = public_transport_usage * time_of_day\")\n",
    "\n",
    "# Add more custom feature engineering based on domain knowledge\n",
    "\n",
    "final_features = data.shape[1]\n",
    "new_features = final_features - initial_features\n",
    "\n",
    "print(f\"\\nüìä New features created: {new_features}\")\n",
    "print(f\"üìä Total features now: {final_features}\")\n",
    "\n",
    "if new_features > 0:\n",
    "    print(\"\\nUpdated dataset shape:\", data.shape)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No new features were created (columns may not exist)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80b06d9",
   "metadata": {},
   "source": [
    "## 5. Scale Numeric Features\n",
    "\n",
    "Standardize numerical features using StandardScaler to ensure all features are on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cb8076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numeric features\n",
    "print(\"=\" * 60)\n",
    "print(\"SCALING NUMERIC FEATURES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "target_col = 'risk'\n",
    "\n",
    "# Identify numeric columns (excluding target)\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "if target_col in numeric_cols:\n",
    "    numeric_cols.remove(target_col)\n",
    "\n",
    "if numeric_cols:\n",
    "    print(f\"\\nüìã Numeric columns to scale ({len(numeric_cols)}): {numeric_cols}\")\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    data_scaled = data.copy()\n",
    "    data_scaled[numeric_cols] = scaler.fit_transform(data[numeric_cols])\n",
    "    \n",
    "    # Save the scaler\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    joblib.dump(scaler, '../models/scaler.pkl')\n",
    "    print(\"\\n‚úÖ Scaler saved to '../models/scaler.pkl'\")\n",
    "    \n",
    "    # Show statistics before and after scaling\n",
    "    print(\"\\n--- Statistics Before Scaling ---\")\n",
    "    print(data[numeric_cols].describe())\n",
    "    \n",
    "    print(\"\\n--- Statistics After Scaling ---\")\n",
    "    print(data_scaled[numeric_cols].describe())\n",
    "    \n",
    "    # Update data with scaled values\n",
    "    data = data_scaled\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No numeric columns found to scale!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd87d0ce",
   "metadata": {},
   "source": [
    "## 6. Split Features and Target\n",
    "\n",
    "Separate features (X) from the target variable (y) for verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ee02af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split features and target\n",
    "print(\"=\" * 60)\n",
    "print(\"SPLITTING FEATURES AND TARGET\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "target_col = 'risk'\n",
    "\n",
    "if target_col in data.columns:\n",
    "    X = data.drop(target_col, axis=1)\n",
    "    y = data[target_col]\n",
    "    \n",
    "    print(f\"\\n‚úÖ Features shape: {X.shape}\")\n",
    "    print(f\"‚úÖ Target shape: {y.shape}\")\n",
    "    \n",
    "    print(f\"\\nüìä Target distribution:\")\n",
    "    print(y.value_counts())\n",
    "    \n",
    "    print(f\"\\nüìä Target distribution (%):\")\n",
    "    print(y.value_counts(normalize=True) * 100)\n",
    "else:\n",
    "    print(f\"\\n‚ùå Error: Target column '{target_col}' not found!\")\n",
    "    print(f\"Available columns: {data.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98739cb",
   "metadata": {},
   "source": [
    "## 7. Save Processed Data\n",
    "\n",
    "Save the feature-engineered dataset for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d5b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save processed data\n",
    "output_path = \"../data/women_risk_processed.csv\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"SAVING PROCESSED DATA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "data.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"\\n‚úÖ Processed data saved to: {output_path}\")\n",
    "print(f\"‚úÖ Shape: {data.shape}\")\n",
    "print(f\"‚úÖ Rows: {data.shape[0]}\")\n",
    "print(f\"‚úÖ Columns: {data.shape[1]}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FEATURE ENGINEERING COMPLETED SUCCESSFULLY!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìå Next Steps:\")\n",
    "print(\"   1. Review the processed data\")\n",
    "print(\"   2. Proceed to model training\")\n",
    "print(\"   3. Use the saved scaler and encoders for predictions\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
